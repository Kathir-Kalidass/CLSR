# Quick Start Guide - CSLR Real-Time System

## ğŸš€ 5-Minute Setup

### Step 1: Backend Setup (2 minutes)

```bash
# Navigate to backend
cd application/UI/backend

# Create virtual environment
python3 -m venv .venv

# Activate virtual environment
source .venv/bin/activate  # Linux/Mac
# OR
.venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run backend
uvicorn main:app --host 0.0.0.0 --port 8080 --reload
```

**Expected output:**
```
INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
INFO:     Started reloader process
INFO:     Started server process
INFO:     Application startup complete
```

### Step 2: Frontend Setup (2 minutes)

**Open a NEW terminal window:**

```bash
# Navigate to frontend
cd application/UI/frontend

# Install dependencies (first time only)
npm install

# Run development server
npm run dev
```

**Expected output:**
```
  VITE v5.x.x  ready in xxx ms

  âœ  Local:   http://localhost:5173/
  âœ  press h to show help
```

### Step 3: Open Browser (1 minute)

1. Go to: `http://localhost:5173`
2. Click **"Start Camera"** button
3. Allow webcam access when prompted
4. Click **"Start"** button to begin inference
5. Watch real-time sign language recognition! ğŸ‰

## âš™ï¸ What's Happening?

### Module 1 Pipeline (Real-Time Processing)

```
ğŸ“¹ Webcam â†’ ğŸ¯ Motion Filter â†’ âœ‚ï¸ Frame Skip â†’ ğŸ¤– MediaPipe 
   â†“
ğŸ”² ROI Crop â†’ ğŸ“ Resize (224Ã—224) â†’ ğŸ“Š Normalize
   â†“
ğŸ§  Pose Normalize â†’ ğŸ’¾ Buffer (64 frames)
   â†“
ğŸ“¤ Ready for Module 2
```

### UI Features You'll See

1. **Video Feed**: Live webcam with pose landmarks
2. **Predicted Gloss**: Current sign predictions
3. **Sentence Output**: Grammar-corrected natural language
4. **Confidence Bar**: Prediction confidence (animated)
5. **Metrics**: FPS, latency, accuracy
6. **Module 1 Debug**: 
   - Buffer fill status
   - Motion score
   - Frame keep/discard stats
   - ROI/Pose detection status
7. **Transcript History**: Recent predictions
8. **Parser Console**: Live module pipeline logs

## ğŸ® Controls

| Button | Action |
|--------|--------|
| **Start** | Begin real-time inference |
| **Stop** | Pause processing |
| **Clear** | Clear transcript history |
| **TTS ON/OFF** | Toggle text-to-speech |
| **Start/Stop Camera** | Control webcam |

## ğŸ“Š Performance Expectations

### On 4GB GPU:
- **FPS**: 15-20
- **Latency**: 250-350ms per window
- **GPU Memory**: <2GB
- **Buffer Fill Rate**: ~1 second to fill 64 frames

### On CPU Only:
- **FPS**: 8-12
- **Latency**: 400-600ms per window
- **Still usable** for demonstration! âœ…

## ğŸ› Quick Troubleshooting

### Backend won't start:

```bash
# Check Python version (need 3.8+)
python --version

# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

### Frontend won't start:

```bash
# Check Node version (need 16+)
node --version

# Clear node_modules and reinstall
rm -rf node_modules
npm install
```

### Camera not working:

```bash
# Test camera in Python
python -c "import cv2; print('Camera OK' if cv2.VideoCapture(0).isOpened() else 'Camera Error')"
```

### WebSocket connection failed:

1. Check backend is running on port 8080
2. Check no firewall blocking
3. Try: `http://localhost:5173` instead of `127.0.0.1`

## ğŸ¯ Demo Mode vs Real Mode

### Current Configuration: **Demo Mode** âœ…

- Uses pretrained ResNet18 for RGB features
- Uses lightweight MLP for pose features
- **Predictions are randomized for demonstration**
- No trained CTC model needed
- Perfect for showcasing architecture!

### To Enable Real Predictions:

Edit `backend/main.py`:

```python
engine = CSLREngine(demo_mode=False)  # Change to False
```

**Note**: Requires trained model weights (not included in this demo).

## ğŸ“ What to Show in Review

1. **Start the system** - Show it boots quickly
2. **Enable camera** - Show real-time processing
3. **Point to Module 1 Debug** - Explain optimization strategies
4. **Show buffer filling** - Explain sliding window
5. **Show predictions** - Explain pipeline flow
6. **Show confidence metrics** - Explain quality monitoring
7. **Show parser console** - Explain module integration

## ğŸ“ Key Talking Points for Review

### Module 1 Optimizations:
- "Motion-based frame filtering reduces processing by 40-60%"
- "Temporal subsampling (1/2) provides 2x speedup"
- "ROI cropping focuses on signing area, improving accuracy"
- "MediaPipe complexity=1 balances accuracy with speed"

### Architecture Highlights:
- "Dual-stream approach combines appearance and motion cues"
- "Attention fusion weights RGB and pose features dynamically"
- "BiLSTM captures temporal dependencies for continuous recognition"
- "Sliding window enables real-time streaming inference"

### Engineering Excellence:
- "Modular design separates concerns across 7 modules"
- "WebSocket provides low-latency real-time communication"
- "React + framer-motion delivers smooth, professional UI"
- "Resource-efficient pipeline runs on 4GB GPU"

## ğŸ‰ You're Ready!

The system should now be running smoothly. Enjoy demonstrating your real-time ISL recognition system! 

**Pro tip**: Practice your demo flow 2-3 times before the actual review to ensure smooth presentation.

---

**Questions?** Check the main README.md for detailed documentation!
